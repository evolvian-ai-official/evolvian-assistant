import os
import logging
from openai import OpenAI

logger = logging.getLogger("llm")

# Inicializa cliente OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Premium calendar models
CALENDAR_MODEL_PREMIUM = "gpt-4.1"
CALENDAR_MODEL_FALLBACK = "gpt-4.1-mini"

# Global fallback (no calendar)
GLOBAL_FALLBACK_MODEL = "gpt-4o-mini"


def openai_chat(
    messages,
    temperature: float = 0.1,
    model: str = None,
    use_calendar_model: bool = False,
    timeout: int = 12
) -> str:
    """
    ============================================================
    Evolvian AI ‚Äî OpenAI Chat Wrapper (Production Grade)
    ------------------------------------------------------------
    - If use_calendar_model=True ‚Üí force premium gpt-4.1
    - Otherwise ‚Üí use provided model or OPENAI_MODEL
    - Includes:
        ‚úî Timeout
        ‚úî Premium fallback
        ‚úî Global fallback
        ‚úî Logging
        ‚úî Error insulation for Render & Supabase pipelines
    ============================================================
    """

    # 1Ô∏è‚É£ Modelo seleccionado seg√∫n el flujo
    if use_calendar_model:
        selected_model = CALENDAR_MODEL_PREMIUM
    else:
        selected_model = model or os.getenv("OPENAI_MODEL", "gpt-4o-mini")

    # 2Ô∏è‚É£ Intento principal
    try:
        response = client.chat.completions.create(
            model=selected_model,
            messages=messages,
            temperature=temperature,
            timeout=timeout,
        )
        content = response.choices[0].message.content.strip()
        logger.info(f"üí¨ OpenAI response ({selected_model}) ‚Üí {content[:180]}...")
        return content

    except Exception as e:
        logger.error(f"‚ùå Error using {selected_model}: {e}")


    # 3Ô∏è‚É£ Fallback exclusivo para calendario (premium ‚Üí mini)
    if use_calendar_model and selected_model != CALENDAR_MODEL_FALLBACK:
        try:
            logger.warning(f"‚ö†Ô∏è Switching to fallback PREMIUM: {CALENDAR_MODEL_FALLBACK}")

            response = client.chat.completions.create(
                model=CALENDAR_MODEL_FALLBACK,
                messages=messages,
                temperature=temperature,
                timeout=timeout,
            )
            content = response.choices[0].message.content.strip()
            return content

        except Exception as e2:
            logger.error(f"‚ùå Calendar fallback (gpt-4.1-mini) also failed: {e2}")


    # 4Ô∏è‚É£ Fallback global (para cualquier flujo NO calendar)
    if not use_calendar_model:
        try:
            logger.warning(f"‚ö†Ô∏è Switching to GLOBAL FALLBACK: {GLOBAL_FALLBACK_MODEL}")

            response = client.chat.completions.create(
                model=GLOBAL_FALLBACK_MODEL,
                messages=messages,
                temperature=temperature,
                timeout=timeout,
            )
            content = response.choices[0].message.content.strip()
            return content

        except Exception as e3:
            logger.error(f"‚ùå Global fallback failed: {e3}")


    # 5Ô∏è‚É£ √öltimo recurso si todo falla
    return "Error: the AI assistant could not process your request."
