"""
BASE5 - Evolvian RAG Final (seguro, flexible y anti-hallucination)
‚úÖ FIX: idioma consistente + system role real + no contaminar question original
"""

import os
import logging
import requests
from tempfile import NamedTemporaryFile
from typing import List, Dict, Optional, Union
import uuid
from api.config.config import DEFAULT_CHAT_MODEL


from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma

from langchain_core.messages import SystemMessage, HumanMessage

from api.modules.assistant_rag.supabase_client import (
    save_history,
    list_documents_with_signed_urls,
)
from api.modules.assistant_rag.prompt_utils import (
    get_prompt_for_client,
    get_temperature_for_client,
    get_language_for_client,  # ‚úÖ NUEVO (abajo te dejo el cambio)
)

# üö´ Desactivar telemetr√≠a de Chroma
os.environ["ANONYMIZED_TELEMETRY"] = "false"
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")


FALLBACK_BY_LANG = {
    "es": "No tengo informaci√≥n para responder esta pregunta.Si tienes una duda relacionada con este negocio y necesitas m√°s detalle, puedes contactarnos directamente. Mientras tanto, con gusto puedo ayudarte con cualquier otra pregunta.",
    "en": "I don‚Äôt have information to answer this question. If you have a question related to this business and need more details, you can contact us directly. In the meantime, I‚Äôm happy to help with any other question.",
}


def get_base_data_path() -> str:
    render_root = "/opt/render/project/src"
    base_dir = os.path.join(render_root, "data") if os.path.exists(render_root) else os.path.join(os.getcwd(), "data")
    os.makedirs(base_dir, exist_ok=True)
    logging.info(f"üìÇ Base data path usada: {base_dir}")
    return base_dir


def load_document(file_path: str) -> List:
    ext = os.path.splitext(file_path)[1].lower()
    if ext == ".pdf":
        loader = PyPDFLoader(file_path)
    elif ext == ".txt":
        loader = TextLoader(file_path)
    else:
        raise ValueError(f"Formato de archivo no soportado: {ext}")
    return loader.load()


def chunk_documents(documents: List) -> List:
    splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=300)
    return splitter.split_documents(documents)


def fetch_signed_documents(client_id: str) -> List[str]:
    try:
        res = list_documents_with_signed_urls(client_id)
        if not res:
            logging.info("üìÇ No hay documentos firmados disponibles.")
            return []
        urls = [doc["signed_url"] for doc in res if doc.get("signed_url")]
        filenames = [url.split("/")[-1].split("?")[0] for url in urls]
        logging.info(f"üìÇ Documentos firmados encontrados: {len(filenames)} ‚Üí {filenames}")
        return urls
    except Exception as e:
        logging.error(f"‚ùå Error al obtener documentos firmados: {e}")
        return []


def _guess_lang_es_en(text: str) -> str:
    """
    Heur√≠stica r√°pida y robusta para detectar ES / EN en mensajes cortos.
    Optimizada para chat real (sin acentos, sin signos).
    """
    t = (text or "").strip().lower()
    if not t:
        return "en"

    # 1Ô∏è‚É£ Se√±ales fuertes de espa√±ol
    if any(c in t for c in "¬ø¬°√±√°√©√≠√≥√∫"):
        return "es"

    # 2Ô∏è‚É£ Palabras funcionales MUY comunes en espa√±ol (chat real)
    es_words = {
        "que", "es", "como", "para", "por", "porque", "cuando", "donde",
        "cual", "cuanto", "cuantos",
        "hola", "buenas", "dame", "quiero", "necesito",
        "informacion", "informaci√≥n", "info",
        "plan", "planes", "precio", "coste", "costo",
        "ayuda", "soporte", "incluye", "incluyen",
        "funciona", "servicio"
    }

    # limpieza b√°sica
    tokens = set(
        t.replace("?", "")
         .replace("¬ø", "")
         .replace("!", "")
         .replace("¬°", "")
         .split()
    )

    if tokens.intersection(es_words):
        return "es"

    # 3Ô∏è‚É£ Default conservador
    return "en"


def _filter_conversation_by_lang(conversation: str, lang: str) -> str:
    """
    Filtra el historial para conservar solo las l√≠neas
    que coinciden con el idioma del turno actual.
    """
    if not conversation:
        return ""

    lines = conversation.split("\n")
    filtered = []

    for line in lines:
        if _guess_lang_es_en(line) == lang:
            filtered.append(line)

    return "\n".join(filtered)



def _safe_langdetect(text: str) -> Optional[str]:
    try:
        from langdetect import detect
        return detect(text)
    except Exception:
        return None


def _resolve_user_language(client_id: str, user_text: str) -> str:
    """
    Decide el idioma del turno seg√∫n el MENSAJE del usuario.
    El idioma del cliente act√∫a solo como fallback.

    Prioridad:
    1) Heur√≠stica ES/EN sobre el mensaje
    2) langdetect (opcional)
    3) client_settings.language
    4) fallback 'en'
    """

    # 1Ô∏è‚É£ Heur√≠stica r√°pida (inputs cortos, chats)
    heuristic = _guess_lang_es_en(user_text)
    if heuristic in ("es", "en"):
        return heuristic

    # 2Ô∏è‚É£ Detecci√≥n probabil√≠stica (backup)
    detected = _safe_langdetect(user_text)
    if detected in ("es", "en"):
        return detected

    # 3Ô∏è‚É£ Idioma configurado del cliente (fallback)
    client_lang = (get_language_for_client(client_id) or "").strip().lower()
    if client_lang.startswith("es"):
        return "es"
    if client_lang.startswith("en"):
        return "en"

    # 4Ô∏è‚É£ √öltimo fallback
    return "en"



def _detect_corpus_language(chunks: List) -> Optional[str]:
    try:
        sample_text = "\n".join(c.page_content for c in chunks[:3] if getattr(c, "page_content", None))
        if not sample_text.strip():
            return None
        detected = _safe_langdetect(sample_text)
        return detected
    except Exception:
        return None


def _translate_text(text: str, target_lang: str) -> str:
    """
    Traduce SOLO para retrieval.
    ‚ùå No afecta idioma de salida final
    ‚ùå No retraduce si ya est√° en el idioma correcto
    ‚úÖ Determinista y controlado
    """
    if not text.strip():
        return text

    # Detectar idioma del texto (heur√≠stico, r√°pido y suficiente)
    detected_lang = _guess_lang_es_en(text)
    if detected_lang == target_lang:
        return text  # üö´ No retraducir

    if target_lang not in ("es", "en"):
        return text  # üö´ No traducir a idiomas no soportados

    llm_tr = ChatOpenAI(
        model="gpt-4o-mini",  # modelo estable y barato
        temperature=0
    )

    target_name = "Spanish" if target_lang == "es" else "English"

    resp = llm_tr.invoke([
        SystemMessage(
            content="You are a translation engine. Return ONLY the translated text."
        ),
        HumanMessage(
            content=f"Translate the following text to {target_name}:\n\n{text}"
        )
    ])

    translated = (resp.content or "").strip()
    return translated or text



def _rewrite_for_retrieval(conversation_memory: str, retrieval_question: str) -> str:
    """
    Reescribe la pregunta SOLO para mejorar retrieval.
    ‚ùå No detecta idioma
    ‚ùå No traduce
    ‚ùå No decide lenguaje
    ‚úÖ Usa exactamente el idioma del texto recibido
    """
    if not retrieval_question or not retrieval_question.strip():
        return retrieval_question

    # Si no hay conversaci√≥n previa, no reescribimos
    if not conversation_memory or not conversation_memory.strip():
        return retrieval_question

    llm_rw = ChatOpenAI(
        model="gpt-4o-mini",  # modelo estable y determinista
        temperature=0
    )

    prompt = f"""
Rewrite the user's question into a clear, standalone question.
Use ONLY the information explicitly present in the conversation.
Do NOT add assumptions or new facts.
If the question is already clear, return it unchanged.

Conversation:
{conversation_memory}

Question:
{retrieval_question}
""".strip()

    resp = llm_rw.invoke([
        SystemMessage(
            content="You rewrite questions for retrieval. Do not add new facts."
        ),
        HumanMessage(content=prompt)
    ])

    rewritten = (resp.content or "").strip()
    return rewritten or retrieval_question



def ask_question(
    messages: Union[List[Dict[str, str]], str],
    client_id: str,
    session_id: str = None,
    disable_rag: bool = False
) -> str:
    try:
        session_id = session_id or str(uuid.uuid4())

        prompt = get_prompt_for_client(client_id)
        temperature = get_temperature_for_client(client_id)
        show_sources = os.getenv("EVOLVIAN_SHOW_SOURCES", "false").lower() == "true"

        # üîß Normalizar mensajes
        if isinstance(messages, list):
            norm_messages = [
                {
                    "role": (m.get("role", "user") or "user").strip(),
                    "content": (m.get("content") or "").strip()
                }
                for m in messages if m.get("content")
            ]
        else:
            norm_messages = [{"role": "user", "content": str(messages).strip()}]

        last_user_msg = next(
            (m for m in reversed(norm_messages) if m["role"] == "user"),
            None
        )
        question = (last_user_msg["content"] if last_user_msg else "").strip()
        if not question:
            return ("No logr√© entender tu mensaje ¬øPodr√≠as intentarlo de nuevo?"
            if turn_lang == "es"
            else "I couldn‚Äôt understand your message. Could you please try again?"
        )

        # ‚úÖ Guardar original SIEMPRE
        original_question = question

        # üîí Idioma del turno (DECISI√ìN √öNICA)
        turn_lang = _resolve_user_language(client_id, original_question)
        fallback = FALLBACK_BY_LANG.get(turn_lang, FALLBACK_BY_LANG["en"])

        logging.info(f"üß© Pregunta procesada: {original_question}")
        logging.info(f"üà∂ Idioma del turno: {turn_lang}")

        # üßπ Construir y filtrar historial por idioma
        convo_tail = norm_messages[-10:]
        raw_conversation_memory = "\n".join(
            f"{'User' if m['role'] == 'user' else 'Assistant'}: {m['content']}"
            for m in convo_tail
        )
        conversation_memory = _filter_conversation_by_lang(
            raw_conversation_memory,
            turn_lang
        )

        # üëã Saludo r√°pido (controlado por idioma del turno)
        greetings = {"hola", "buenas", "hello", "hi", "hey"}
        if original_question.lower() in greetings:
            answer = (
                "¬°Hola! ¬øEn qu√© puedo ayudarte hoy?"
                if turn_lang == "es"
                else "Hi! How can I help you today?"
            )
            save_history(client_id, session_id, "user", original_question, channel="chat")
            save_history(client_id, session_id, "assistant", answer, channel="chat")
            return answer

        # =====================================================
        # üöÄ Modo directo (sin RAG)
        # =====================================================
        if disable_rag:
            logging.info("üß† RAG disabled ‚Äî using direct mode.")
            llm_direct = ChatOpenAI(temperature=temperature)

            system_direct = SystemMessage(
                content=f"""
{prompt.strip() if prompt else ''}

Rules:
- Respond in {"Spanish" if turn_lang == "es" else "English"}.
- Be concise, professional, and helpful.
""".strip()
            )

            resp = llm_direct.invoke([
                system_direct,
                HumanMessage(content=original_question)
            ])
            answer = (resp.content or "").strip() or fallback

            save_history(client_id, session_id, "user", original_question, channel="chat")
            save_history(client_id, session_id, "assistant", answer, channel="chat")
            return answer

        # =====================================================
        # üìÇ Documentos
        # =====================================================
        logging.info(f"üìÇ Buscando documentos para cliente {client_id}...")
        signed_urls = fetch_signed_documents(client_id)
        if not signed_urls:
            return (
                "En este momento no puedo responder preguntas. Por favor, intenta m√°s tarde."
                if turn_lang == "es"
                else "I can‚Äôt answer questions at the moment. Please try again later."
            )

        # üìë Descargar y trocear
        all_chunks = []
        for url in signed_urls:
            try:
                filename = url.split("/")[-1].split("?")[0]
                resp = requests.get(url, timeout=15)
                if resp.status_code != 200:
                    continue

                suffix = ".pdf" if filename.lower().endswith(".pdf") else ".txt"
                with NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:
                    tmp_file.write(resp.content)
                    tmp_file.flush()

                    docs = load_document(tmp_file.name)
                    chunks = chunk_documents(docs)

                    for ch in chunks:
                        ch.metadata["source"] = filename
                        ch.metadata["tenant_id"] = client_id

                    all_chunks.extend(chunks)

                logging.info(f"‚úÇÔ∏è {filename} ‚Üí {len(chunks)} chunks")
            except Exception as e:
                logging.warning(f"‚ùå Error procesando {url}: {e}")

        if not all_chunks:
            return (
                "En este momento no puedo responder preguntas. Por favor, intenta m√°s tarde."
                if turn_lang == "es"
                else "I can‚Äôt answer questions at the moment. Please try again later."
            )

        # =====================================================
        # üà∂ Idioma del corpus (SOLO para retrieval)
        # =====================================================
        corpus_lang = _detect_corpus_language(all_chunks)
        logging.info(f"üà∂ Idioma del corpus: {corpus_lang}")

        retrieval_question = original_question
        if corpus_lang in ("es", "en") and corpus_lang != turn_lang:
            retrieval_question = _translate_text(original_question, corpus_lang)

        # ‚úèÔ∏è Rewrite SIEMPRE en idioma del usuario
        rewritten_question = _rewrite_for_retrieval(
            conversation_memory,
            retrieval_question
        )

        # =====================================================
        # üîç Recuperaci√≥n
        # =====================================================
        BASE_DATA_DIR = get_base_data_path()
        client_data_path = os.path.join(BASE_DATA_DIR, client_id)
        os.makedirs(client_data_path, exist_ok=True)

        embeddings = OpenAIEmbeddings()
        vectordb = Chroma.from_documents(
            all_chunks,
            embeddings,
            persist_directory=client_data_path,
            collection_name=client_id
        )

        retriever = vectordb.as_retriever(
            search_type="mmr",
            search_kwargs={"k": 20, "lambda_mult": 0.5}
        )
        retrieved_docs = retriever.invoke(rewritten_question)

        if not retrieved_docs:
            save_history(client_id, session_id, "user", original_question, channel="chat")
            save_history(client_id, session_id, "assistant", fallback, channel="chat")
            return fallback

        # =====================================================
        # üß© Construir contexto
        # =====================================================
        MAX_CHARS = 9000
        context_text, total = "", 0
        for d in retrieved_docs:
            text = (d.page_content or "").strip()
            if not text:
                continue
            remaining = MAX_CHARS - total
            context_text += text[:remaining] + "\n\n"
            total += len(text)
            if total >= MAX_CHARS:
                break

        sources = list({d.metadata.get("source", "unknown") for d in retrieved_docs})

        # =====================================================
        # üß± System Prompt FINAL
        # =====================================================
        language_rule = (
            "Responde SIEMPRE en espa√±ol."
            if turn_lang == "es"
            else "Always respond in English."
        )

        system_prompt = f"""
You are a helpful AI assistant representative of this business that answers questions ONLY with the information provided by the business.

{prompt.strip() if prompt else ''}

Core Rules:
- You MUST use ONLY the information provided.
- If the answer is not clearly found, reply exactly: "{fallback}"
- Never use external knowledge.
- {language_rule}
- Never mention the words "context" or "document".
""".strip()

        human_prompt = f"""
<conversation>
{conversation_memory}
</conversation>

<information>
{context_text}
</information>

<question>
{original_question}
</question>
""".strip()

        
        llm = ChatOpenAI(
            model=DEFAULT_CHAT_MODEL,
            temperature=temperature
        )
        raw = llm.invoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=human_prompt)
        ])
        answer = (raw.content or "").strip() or fallback

        # =====================================================
        # üõ°Ô∏è Anti-hallucination (solo si idioma coincide)
        # =====================================================
        if corpus_lang == turn_lang:
            keywords = [w.lower() for w in context_text.split()[:80]]
            if answer != fallback and not any(k in answer.lower() for k in keywords):
                answer = fallback

        if show_sources and answer != fallback and sources:
            answer += "\n\nSources: " + ", ".join(sources)

        # üíæ Guardar historial
        save_history(client_id, session_id, "user", original_question, channel="chat")
        save_history(client_id, session_id, "assistant", answer, channel="chat")

        logging.info(f"‚úÖ Respuesta generada para {client_id}: {answer}")
        return answer

    except Exception as e:
        logging.exception(f"‚ùå Error inesperado procesando pregunta para {client_id}: {e}")
        return (
            "Ups, ocurri√≥ un problema inesperado. Por favor intenta de nuevo."
            if turn_lang == "es"
            else "Oops, something went wrong. Please try again."
        )


# ------------------------------------------------------------------
# üîÅ Alias de compatibilidad para canales externos (WhatsApp, Email)
# NO rompe widget ni flujos existentes
# ------------------------------------------------------------------

async def handle_message(
    client_id: str,
    session_id: str,
    user_message: str,
    channel: str = "chat"
) -> str:
    result = ask_question(
        messages=user_message,
        client_id=client_id,
        session_id=session_id
    )

    # üõ°Ô∏è Blindaje total: si es coroutine, la resolvemos
    if hasattr(result, "__await__"):
        result = await result

    return str(result)
